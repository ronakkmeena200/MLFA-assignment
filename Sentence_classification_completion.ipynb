{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Assignment 3 \n",
    "*  Anirudh Gupta         18ME10006\n",
    "*  Rahul Kumar Meena     18EC30033\n",
    "*  Shreyans Ray          18ME10084"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Sentence classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>Outer space is not friendly to life. Extreme t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Tennis, original name lawn tennis, game in whi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>One woman who frequently flew on Southwest was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>In December 2019, almost seven years after the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>Any life-forms that somehow find themselves in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>science</td>\n",
       "      <td>As small communities, new research shows, some...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>science</td>\n",
       "      <td>Balls of Deinococcus bacteria as thin as five ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>science</td>\n",
       "      <td>They stayed there for three years. Microbes in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>science</td>\n",
       "      <td>The group’s outer layers had shielded them fro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>science</td>\n",
       "      <td>It was known that microbes could survive insid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>science</td>\n",
       "      <td>“It suggests life can survive on its own in sp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>science</td>\n",
       "      <td>Cramm is a microbiologist at the University of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>science</td>\n",
       "      <td>She says the new finding adds weight to the wo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>science</td>\n",
       "      <td>Akihiko Yamagishi is an astrobiologist. He wor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>science</td>\n",
       "      <td>He was part of a team that sent dried pellets ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>science</td>\n",
       "      <td>These radiation-resistant microbes thrive in e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>science</td>\n",
       "      <td>The bacteria were stuffed into small wells in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>science</td>\n",
       "      <td>Back home, researchers moistened the pellets. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>science</td>\n",
       "      <td>After three years in space, bacteria in 100-mi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>science</td>\n",
       "      <td>DNA studies suggested that radiation had fried...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>science</td>\n",
       "      <td>The outer layers of pellets that were 500- to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>science</td>\n",
       "      <td>They were discolored by ultraviolet radiation ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>science</td>\n",
       "      <td>About four in every 100 of the microbes in tho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sports</td>\n",
       "      <td>Points are awarded to a player or team wheneve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sports</td>\n",
       "      <td>Organized tennis is played according to rules ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sports</td>\n",
       "      <td>Tennis originally was known as lawn tennis, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sports</td>\n",
       "      <td>It is now played on a variety of surfaces. The...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sports</td>\n",
       "      <td>This ancient game is still played to a limited...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sports</td>\n",
       "      <td>Its period of most rapid growth as both a part...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sports</td>\n",
       "      <td>While tennis can be enjoyed by players of prac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>business</td>\n",
       "      <td>So Bethune trusted his people over unreasonabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>business</td>\n",
       "      <td>Of course, there are plenty of examples of bad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>business</td>\n",
       "      <td>Using the slogan “The customer is always right...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>business</td>\n",
       "      <td>Also, it means that abusive people get better ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>business</td>\n",
       "      <td>Most businesses think that “the more customers...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>business</td>\n",
       "      <td>One of our service technicians arrived at a cu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>business</td>\n",
       "      <td>When he’d finished the task and returned to th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>business</td>\n",
       "      <td>Just like Kelleher dismissed the irate lady wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>business</td>\n",
       "      <td>Note that it was not even a matter of a financ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>business</td>\n",
       "      <td>Rosenbluth argues that when you put the employ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>covid</td>\n",
       "      <td>The Coronavirus (CoV) is a large family of vir...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>covid</td>\n",
       "      <td>The severity of the infection may be visible a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>covid</td>\n",
       "      <td>Until the outbreak of SARS, this group of viru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>covid</td>\n",
       "      <td>On December 31, 2019, mysterious cases of pneu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>covid</td>\n",
       "      <td>On January 7, 2020, the causative agent was id...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>covid</td>\n",
       "      <td>The virus spread extensively in the Wuhan regi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>covid</td>\n",
       "      <td>Though experts suspected that the virus is tra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>covid</td>\n",
       "      <td>There are no treatment options available for t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>covid</td>\n",
       "      <td>For the containment of the virus, it is recomm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>covid</td>\n",
       "      <td>The virus has had a significant socio-economic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>covid</td>\n",
       "      <td>Coronaviridae is a family of viruses with a po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>covid</td>\n",
       "      <td>When looked at with the help of an electron mi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>covid</td>\n",
       "      <td>This family of viruses mainly cause respirator...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>covid</td>\n",
       "      <td>These viruses can infect animals as well. Up u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>covid</td>\n",
       "      <td>However, after the SARS (severe acute respirat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>covid</td>\n",
       "      <td>This also happened to be the first epidemic of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>covid</td>\n",
       "      <td>Almost 10 years later, there was a MERS (Middl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>covid</td>\n",
       "      <td>Both SARS and MERS have a zoonotic origin and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>covid</td>\n",
       "      <td>The zoonotic origin of these viruses allows th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>covid</td>\n",
       "      <td>Coronaviruses are known to use the angiotensin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                               text Unnamed: 2  \\\n",
       "0    science  Outer space is not friendly to life. Extreme t...        NaN   \n",
       "1     sports  Tennis, original name lawn tennis, game in whi...        NaN   \n",
       "2   business  One woman who frequently flew on Southwest was...        NaN   \n",
       "3      covid  In December 2019, almost seven years after the...        NaN   \n",
       "4    science  Any life-forms that somehow find themselves in...        NaN   \n",
       "5    science  As small communities, new research shows, some...        NaN   \n",
       "6    science  Balls of Deinococcus bacteria as thin as five ...        NaN   \n",
       "7    science  They stayed there for three years. Microbes in...        NaN   \n",
       "8    science  The group’s outer layers had shielded them fro...        NaN   \n",
       "9    science  It was known that microbes could survive insid...        NaN   \n",
       "10   science  “It suggests life can survive on its own in sp...        NaN   \n",
       "11   science  Cramm is a microbiologist at the University of...        NaN   \n",
       "12   science  She says the new finding adds weight to the wo...        NaN   \n",
       "13   science  Akihiko Yamagishi is an astrobiologist. He wor...        NaN   \n",
       "14   science  He was part of a team that sent dried pellets ...        NaN   \n",
       "15   science  These radiation-resistant microbes thrive in e...        NaN   \n",
       "16   science  The bacteria were stuffed into small wells in ...        NaN   \n",
       "17   science  Back home, researchers moistened the pellets. ...        NaN   \n",
       "18   science  After three years in space, bacteria in 100-mi...        NaN   \n",
       "19   science  DNA studies suggested that radiation had fried...        NaN   \n",
       "20   science  The outer layers of pellets that were 500- to ...        NaN   \n",
       "21   science  They were discolored by ultraviolet radiation ...        NaN   \n",
       "22   science  About four in every 100 of the microbes in tho...        NaN   \n",
       "23    sports  Points are awarded to a player or team wheneve...        NaN   \n",
       "24    sports  Organized tennis is played according to rules ...        NaN   \n",
       "25    sports  Tennis originally was known as lawn tennis, an...        NaN   \n",
       "26    sports  It is now played on a variety of surfaces. The...        NaN   \n",
       "27    sports  This ancient game is still played to a limited...        NaN   \n",
       "28    sports  Its period of most rapid growth as both a part...        NaN   \n",
       "29    sports  While tennis can be enjoyed by players of prac...        NaN   \n",
       "..       ...                                                ...        ...   \n",
       "50  business  So Bethune trusted his people over unreasonabl...        NaN   \n",
       "51  business  Of course, there are plenty of examples of bad...        NaN   \n",
       "52  business  Using the slogan “The customer is always right...        NaN   \n",
       "53  business  Also, it means that abusive people get better ...        NaN   \n",
       "54  business  Most businesses think that “the more customers...        NaN   \n",
       "55  business  One of our service technicians arrived at a cu...        NaN   \n",
       "56  business  When he’d finished the task and returned to th...        NaN   \n",
       "57  business  Just like Kelleher dismissed the irate lady wh...        NaN   \n",
       "58  business  Note that it was not even a matter of a financ...        NaN   \n",
       "59  business  Rosenbluth argues that when you put the employ...        NaN   \n",
       "60     covid  The Coronavirus (CoV) is a large family of vir...        NaN   \n",
       "61     covid  The severity of the infection may be visible a...        NaN   \n",
       "62     covid  Until the outbreak of SARS, this group of viru...        NaN   \n",
       "63     covid  On December 31, 2019, mysterious cases of pneu...        NaN   \n",
       "64     covid  On January 7, 2020, the causative agent was id...        NaN   \n",
       "65     covid  The virus spread extensively in the Wuhan regi...        NaN   \n",
       "66     covid  Though experts suspected that the virus is tra...        NaN   \n",
       "67     covid  There are no treatment options available for t...        NaN   \n",
       "68     covid  For the containment of the virus, it is recomm...        NaN   \n",
       "69     covid  The virus has had a significant socio-economic...        NaN   \n",
       "70     covid  Coronaviridae is a family of viruses with a po...        NaN   \n",
       "71     covid  When looked at with the help of an electron mi...        NaN   \n",
       "72     covid  This family of viruses mainly cause respirator...        NaN   \n",
       "73     covid  These viruses can infect animals as well. Up u...        NaN   \n",
       "74     covid  However, after the SARS (severe acute respirat...        NaN   \n",
       "75     covid  This also happened to be the first epidemic of...        NaN   \n",
       "76     covid  Almost 10 years later, there was a MERS (Middl...        NaN   \n",
       "77     covid  Both SARS and MERS have a zoonotic origin and ...        NaN   \n",
       "78     covid  The zoonotic origin of these viruses allows th...        NaN   \n",
       "79     covid  Coronaviruses are known to use the angiotensin...        NaN   \n",
       "\n",
       "   Unnamed: 3 Unnamed: 4 Unnamed: 5  \n",
       "0         NaN        NaN        NaN  \n",
       "1         NaN        NaN        NaN  \n",
       "2         NaN        NaN        NaN  \n",
       "3         NaN        NaN        NaN  \n",
       "4         NaN        NaN        NaN  \n",
       "5         NaN        NaN        NaN  \n",
       "6         NaN        NaN        NaN  \n",
       "7         NaN        NaN        NaN  \n",
       "8         NaN        NaN        NaN  \n",
       "9         NaN        NaN        NaN  \n",
       "10        NaN        NaN        NaN  \n",
       "11        NaN        NaN        NaN  \n",
       "12        NaN        NaN        NaN  \n",
       "13        NaN        NaN        NaN  \n",
       "14        NaN        NaN        NaN  \n",
       "15        NaN        NaN        NaN  \n",
       "16        NaN        NaN        NaN  \n",
       "17        NaN        NaN        NaN  \n",
       "18        NaN        NaN        NaN  \n",
       "19        NaN        NaN        NaN  \n",
       "20        NaN        NaN        NaN  \n",
       "21        NaN        NaN        NaN  \n",
       "22        NaN        NaN        NaN  \n",
       "23        NaN        NaN        NaN  \n",
       "24        NaN        NaN        NaN  \n",
       "25        NaN        NaN        NaN  \n",
       "26        NaN        NaN        NaN  \n",
       "27        NaN        NaN        NaN  \n",
       "28        NaN        NaN        NaN  \n",
       "29        NaN        NaN        NaN  \n",
       "..        ...        ...        ...  \n",
       "50        NaN        NaN        NaN  \n",
       "51        NaN        NaN        NaN  \n",
       "52        NaN        NaN        NaN  \n",
       "53        NaN        NaN        NaN  \n",
       "54        NaN        NaN        NaN  \n",
       "55        NaN        NaN        NaN  \n",
       "56        NaN        NaN        NaN  \n",
       "57        NaN        NaN        NaN  \n",
       "58        NaN        NaN        NaN  \n",
       "59        NaN        NaN        NaN  \n",
       "60        NaN        NaN        NaN  \n",
       "61        NaN        NaN        NaN  \n",
       "62        NaN        NaN        NaN  \n",
       "63        NaN        NaN        NaN  \n",
       "64        NaN        NaN        NaN  \n",
       "65        NaN        NaN        NaN  \n",
       "66        NaN        NaN        NaN  \n",
       "67        NaN        NaN        NaN  \n",
       "68        NaN        NaN        NaN  \n",
       "69        NaN        NaN        NaN  \n",
       "70        NaN        NaN        NaN  \n",
       "71        NaN        NaN        NaN  \n",
       "72        NaN        NaN        NaN  \n",
       "73        NaN        NaN        NaN  \n",
       "74        NaN        NaN        NaN  \n",
       "75        NaN        NaN        NaN  \n",
       "76        NaN        NaN        NaN  \n",
       "77        NaN        NaN        NaN  \n",
       "78        NaN        NaN        NaN  \n",
       "79        NaN        NaN        NaN  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                            ## Reading Data Files##\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"traindata.csv\")\n",
    "df1= pd.read_csv(\"testdata.csv\")\n",
    "df40 = pd.read_csv(\"40.csv\")\n",
    "df10= pd.read_csv(\"10.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                   ## Function for filtering the words ##\n",
    "    \n",
    "def filtering(ls ):\n",
    "    \n",
    "    \n",
    "    table = str.maketrans('', '', string.punctuation)                   #Removes Punctuation\n",
    "    stripped = [w.translate(table) for w in ls]\n",
    "  \n",
    "\n",
    "    final = [w.lower() for w in stripped]                              #Makes word lowercase\n",
    " \n",
    "   \n",
    "    from nltk.corpus import stopwords                                  #Removes Stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    filtered_sentence = [] \n",
    "\n",
    "    for w in final: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "        \n",
    "\n",
    "    from nltk.stem import PorterStemmer                                #Porter Stemming of words\n",
    "    FinalSet=[]\n",
    "    ps = PorterStemmer()\n",
    "    for i in filtered_sentence:\n",
    "        trial=ps.stem(i)\n",
    "        FinalSet.append(trial)\n",
    "    FinalSet\n",
    "\n",
    "\n",
    "   \n",
    "    return FinalSet                                                   #returns Final words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in Full vocab after removing duplicates = 726\n"
     ]
    }
   ],
   "source": [
    "                        ## Calling filtering function and making vocabulary of all words ##\n",
    "    \n",
    "n= len(df)\n",
    "ls=[]\n",
    "for i in range(n):\n",
    "    ls+= df.text[i].split()\n",
    "full_vocab =filtering(ls)                                                #filtering full vocab\n",
    "full_vocab = list(Counter(full_vocab))                                   #removes duplicates\n",
    "n_fv =len(full_vocab)\n",
    "print('Number of words in Full vocab after removing duplicates =',n_fv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>science</th>\n",
       "      <th>sports</th>\n",
       "      <th>business</th>\n",
       "      <th>covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   science  sports  business     covid\n",
       "0     0.25    0.25  0.238095  0.261905"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                              ## prior distribution ##\n",
    "\n",
    "category = df.category.values\n",
    "clas =Counter(category)\n",
    "\n",
    "prior_dist_df1 = pd.DataFrame.from_dict(clas, orient='index')\n",
    "prior_dist_df = (prior_dist_df1.T+1)/(n+4)                                #Probability using Laplace smoothing\n",
    "\n",
    "class_label =list(clas)\n",
    "prior_dist_df1 =prior_dist_df1.T\n",
    "prior_dist_df                                                             #DataFrame for prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                         ## Making a Vocab for each class ##\n",
    "    \n",
    "# This vocab will be used for calculating Class conditional distribution\n",
    "\n",
    "\n",
    "topic=[]\n",
    "for i in range(len(class_label)):\n",
    "    ls1=[]\n",
    "   \n",
    "    for j in range(n):\n",
    "        if df.category[j] ==class_label[i] :            \n",
    "            ls1 += df.text[j].split()\n",
    "            \n",
    "    topic.append(ls1)  \n",
    "    topic[i] = filtering(topic[i])                # topic[i] conatins vocab of each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(726, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.47978953, 0.19056487, 0.10359092, 0.22605468],\n",
       "       [0.80880494, 0.05840811, 0.06350121, 0.06928574],\n",
       "       [0.43475306, 0.17267709, 0.18773428, 0.20483558],\n",
       "       ...,\n",
       "       [0.22013726, 0.17487013, 0.19011854, 0.41487407],\n",
       "       [0.22013726, 0.17487013, 0.19011854, 0.41487407],\n",
       "       [0.22013726, 0.17487013, 0.19011854, 0.41487407]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                  ## Calculating class conditional distribution ##\n",
    "    \n",
    "class_condn = np.zeros((n_fv,len(class_label)))\n",
    "for i in range(n_fv):    \n",
    "    for j in range(len(class_label)):\n",
    "        \n",
    "        \n",
    "        nk= topic[j].count(full_vocab[i])                               #keeps track of count each word in each class i\n",
    "        class_condn[i,j] =(nk+1)/(len(topic[j])+n_fv)                    #prob of each word in class i with laplace smoothing\n",
    "    class_condn[i,:]= class_condn[i,:]/ np.sum(class_condn[i,:])\n",
    "       \n",
    "        \n",
    "print(class_condn.shape)                           ###class_condn contains 726 rows corresponding to each word and column \n",
    "class_condn                                       #represent the class conditional prob of that word respective to class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                            ## Predicting Class of Test data ## \n",
    "    \n",
    "    \n",
    "n1= len(df1)                                                      #df1 is dataframe of testdata         \n",
    "ls2=[]\n",
    "pdf= pd.DataFrame([])                                           #empty dataframe to store posterior distribution\n",
    "pred =[]; max=[] ; test_label=[]\n",
    "for i in range(n1):\n",
    "    \n",
    "    ls2= df1.text[i].split()\n",
    "    contents = filtering(ls2)                                     #filtering test sentence\n",
    "    p=np.ones((1,4))\n",
    "    \n",
    "    for x in contents:                                            #looks for the words from test sentence in full_vocab\n",
    "        for j in range(n_fv):\n",
    "            if x == full_vocab[j]:                              \n",
    "                p =np.multiply(class_condn[j],p)                 \n",
    "                break\n",
    "\n",
    "    p =np.multiply(p,np.array(prior_dist_df[0:]))                #multiplying class conditional prob with prior prob \n",
    "    p = p/np.sum(p,axis=1)                                       #converting p to probabiltiy\n",
    "    \n",
    "    \n",
    "    temp = pd.DataFrame(p) \n",
    "    pred.append(class_label[np.argmax(p,axis=1)[0]]); max.append(np.max(p,axis=1)[0])\n",
    "    test_label.append(df1.category[i])\n",
    "    pdf =pdf.append(temp)              \n",
    "                                                                ### p is array with 4 values each value of index i represents\n",
    "                                                                  # posterior probabiltiy###     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_science</th>\n",
       "      <th>prob_sports</th>\n",
       "      <th>prob_business</th>\n",
       "      <th>prob_covid</th>\n",
       "      <th>Category</th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Prob of Preicted Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.996234e-01</td>\n",
       "      <td>2.642789e-05</td>\n",
       "      <td>4.156485e-05</td>\n",
       "      <td>3.085672e-04</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "      <td>0.999623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.483081e-01</td>\n",
       "      <td>4.449265e-03</td>\n",
       "      <td>1.985094e-01</td>\n",
       "      <td>4.873329e-02</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "      <td>0.748308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.951086e-01</td>\n",
       "      <td>1.719662e-04</td>\n",
       "      <td>3.528555e-03</td>\n",
       "      <td>1.190888e-03</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "      <td>0.995109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.999182e-01</td>\n",
       "      <td>4.543284e-06</td>\n",
       "      <td>5.509491e-05</td>\n",
       "      <td>2.213652e-05</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "      <td>0.999918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.811741e-01</td>\n",
       "      <td>4.268098e-02</td>\n",
       "      <td>5.223620e-02</td>\n",
       "      <td>2.239087e-01</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "      <td>0.681174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.969953e-09</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>7.923316e-08</td>\n",
       "      <td>7.415949e-10</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.259883e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.853048e-11</td>\n",
       "      <td>2.551702e-10</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.365876e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.431802e-08</td>\n",
       "      <td>6.725256e-08</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.796961e-02</td>\n",
       "      <td>9.752701e-01</td>\n",
       "      <td>2.367084e-03</td>\n",
       "      <td>4.393163e-03</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.975270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.843150e-05</td>\n",
       "      <td>9.978963e-01</td>\n",
       "      <td>2.061495e-03</td>\n",
       "      <td>1.375652e-05</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.997896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.680945e-13</td>\n",
       "      <td>2.761153e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.611066e-13</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.873726e-02</td>\n",
       "      <td>3.883516e-03</td>\n",
       "      <td>9.505881e-01</td>\n",
       "      <td>6.791106e-03</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>0.950588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.465556e-01</td>\n",
       "      <td>9.247972e-02</td>\n",
       "      <td>6.246348e-01</td>\n",
       "      <td>1.363299e-01</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>0.624635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.500838e-02</td>\n",
       "      <td>5.976158e-03</td>\n",
       "      <td>9.542219e-01</td>\n",
       "      <td>2.479352e-02</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>0.954222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.082551e-10</td>\n",
       "      <td>5.853190e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.324356e-10</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.519001e-04</td>\n",
       "      <td>6.201673e-04</td>\n",
       "      <td>1.921494e-04</td>\n",
       "      <td>9.985358e-01</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "      <td>0.998536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.308777e-04</td>\n",
       "      <td>9.693024e-06</td>\n",
       "      <td>3.918137e-05</td>\n",
       "      <td>9.997202e-01</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "      <td>0.999720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.018221e-04</td>\n",
       "      <td>7.694700e-05</td>\n",
       "      <td>5.183950e-05</td>\n",
       "      <td>9.997694e-01</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "      <td>0.999769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.267138e-05</td>\n",
       "      <td>3.696010e-06</td>\n",
       "      <td>1.788233e-05</td>\n",
       "      <td>9.999458e-01</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "      <td>0.999946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.574390e-04</td>\n",
       "      <td>6.675797e-04</td>\n",
       "      <td>1.902499e-04</td>\n",
       "      <td>9.985847e-01</td>\n",
       "      <td>covid</td>\n",
       "      <td>covid</td>\n",
       "      <td>0.998585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob_science   prob_sports  prob_business    prob_covid  Category  \\\n",
       "index                                                                      \n",
       "1      9.996234e-01  2.642789e-05   4.156485e-05  3.085672e-04   science   \n",
       "2      7.483081e-01  4.449265e-03   1.985094e-01  4.873329e-02   science   \n",
       "3      9.951086e-01  1.719662e-04   3.528555e-03  1.190888e-03   science   \n",
       "4      9.999182e-01  4.543284e-06   5.509491e-05  2.213652e-05   science   \n",
       "5      6.811741e-01  4.268098e-02   5.223620e-02  2.239087e-01   science   \n",
       "6      6.969953e-09  9.999999e-01   7.923316e-08  7.415949e-10    sports   \n",
       "7      2.259883e-09  1.000000e+00   8.853048e-11  2.551702e-10    sports   \n",
       "8      4.365876e-08  9.999999e-01   1.431802e-08  6.725256e-08    sports   \n",
       "9      1.796961e-02  9.752701e-01   2.367084e-03  4.393163e-03    sports   \n",
       "10     2.843150e-05  9.978963e-01   2.061495e-03  1.375652e-05    sports   \n",
       "11     8.680945e-13  2.761153e-14   1.000000e+00  2.611066e-13  business   \n",
       "12     3.873726e-02  3.883516e-03   9.505881e-01  6.791106e-03  business   \n",
       "13     1.465556e-01  9.247972e-02   6.246348e-01  1.363299e-01  business   \n",
       "14     1.500838e-02  5.976158e-03   9.542219e-01  2.479352e-02  business   \n",
       "15     3.082551e-10  5.853190e-10   1.000000e+00  1.324356e-10  business   \n",
       "16     6.519001e-04  6.201673e-04   1.921494e-04  9.985358e-01     covid   \n",
       "17     2.308777e-04  9.693024e-06   3.918137e-05  9.997202e-01     covid   \n",
       "18     1.018221e-04  7.694700e-05   5.183950e-05  9.997694e-01     covid   \n",
       "19     3.267138e-05  3.696010e-06   1.788233e-05  9.999458e-01     covid   \n",
       "20     5.574390e-04  6.675797e-04   1.902499e-04  9.985847e-01     covid   \n",
       "\n",
       "      Predicted Class  Prob of Preicted Class  \n",
       "index                                          \n",
       "1             science                0.999623  \n",
       "2             science                0.748308  \n",
       "3             science                0.995109  \n",
       "4             science                0.999918  \n",
       "5             science                0.681174  \n",
       "6              sports                1.000000  \n",
       "7              sports                1.000000  \n",
       "8              sports                1.000000  \n",
       "9              sports                0.975270  \n",
       "10             sports                0.997896  \n",
       "11           business                1.000000  \n",
       "12           business                0.950588  \n",
       "13           business                0.624635  \n",
       "14           business                0.954222  \n",
       "15           business                1.000000  \n",
       "16              covid                0.998536  \n",
       "17              covid                0.999720  \n",
       "18              covid                0.999769  \n",
       "19              covid                0.999946  \n",
       "20              covid                0.998585  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                      ## Dataframe of Results of Prediction##\n",
    "    \n",
    "pdf.columns =['prob_science', 'prob_sports','prob_business','prob_covid'] \n",
    "pdf['Category'] =test_label                       \n",
    "pdf['Predicted Class']=pred                                                       \n",
    "pdf['Prob of Preicted Class'] =max\n",
    "indes =[i+1 for i in range (n1)]; pdf['index'] =indes\n",
    "pdf.set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentence Completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words in Vocab = 337\n"
     ]
    }
   ],
   "source": [
    "                                        ## Vocabulary of all words in 40.csv ##\n",
    "    \n",
    "n_2=len(df40)\n",
    "l2=[]\n",
    "for i in range(n_2):\n",
    "    l2 += df40.text[i].split()\n",
    "group = filtering(l2)                                      #List containing all words \n",
    "vocab_2=list(Counter(group))                               #removes duplicate from vocab\n",
    "n_fv2 =len(vocab_2)\n",
    "print('Number of Words in Vocab =',n_fv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sum of all prior probability= 0.9999999999999966\n"
     ]
    }
   ],
   "source": [
    "                                              ## Prior Distribution ##\n",
    "PD_w=[]\n",
    "for x in vocab_2:\n",
    "    PD_w.append(group.count(x)/len(group))         \n",
    "print(' Sum of all prior probability=',sum(PD_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                      ## Class Conditional probability Of each word ## \n",
    "\n",
    "class_cond2 =np.zeros((n_fv2,n_fv2)) \n",
    "for i in range(n_fv2):                                   #class_word or row of class_cond2\n",
    "    temp=[] \n",
    "    l=0\n",
    "    for j in range(n_2) :                               #column for each class in class_cond2\n",
    "        \n",
    "        \n",
    "        temp1 = filtering(df40.text[j].split())         #filters word\n",
    "        temp1 = list(Counter(temp1))                    #removes duplicate\n",
    "\n",
    "        \n",
    "        if vocab_2[i] in temp1:                         #checks sentence if contains class_word \n",
    "            temp+=temp1                                 #adds all words of sentence to a list\n",
    "            l+=1                                        #counts the number of sentence having class_word\n",
    "\n",
    "    for k in range(n_fv2):                              #for assigning class cond prob to each word in vocab for class_word\n",
    "        nk =temp.count(vocab_2[k]) \n",
    "        class_cond2[k,i]+=(nk+1)/(l+n_fv2)              # assigns prob with laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Eating healthy food is important for maintainng good _____ food\n",
      "  Prob of chosen word = 0.542353618160035\n",
      "\n",
      "\n",
      "2 Following a healthy diet will boost your _____ healthi\n",
      "  Prob of chosen word = 0.503158001202429\n",
      "\n",
      "\n",
      "3 Avoid eating chemical additives, added sugars in your diet. Switch to a healthy ____ food\n",
      "  Prob of chosen word = 0.45006732953936474\n",
      "\n",
      "\n",
      "4 Your diet should be rich of vitamins D,K, calcium and ______ diet\n",
      "  Prob of chosen word = 0.3772323502596601\n",
      "\n",
      "\n",
      "5 The healthier the food you eat, the better you’ll feel after a _____. food\n",
      "  Prob of chosen word = 0.5754526085873335\n",
      "\n",
      "\n",
      "6 Dehydration causes tiredness, low energy and head aches. Drink plenty of ______ energi\n",
      "  Prob of chosen word = 0.2367365898130446\n",
      "\n",
      "\n",
      "7 People with kidney disease should avoid eating high amounts of ______ food\n",
      "  Prob of chosen word = 0.4126314428282017\n",
      "\n",
      "\n",
      "8 We should avoid eating transfats. Eating healthy fats and dietary fibre can help us lose ____ food\n",
      "  Prob of chosen word = 0.617931423559169\n",
      "\n",
      "\n",
      "9 Mindless eating is often caused by eating alone. We should avoid eating while we are in front of a TV or a ______ eat\n",
      "  Prob of chosen word = 0.9759192736906349\n",
      "\n",
      "\n",
      "10 Eating more junk food will make you feel uncomfortable and _____ food\n",
      "  Prob of chosen word = 0.6257524068245784\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "                                    ## Prediction of words fro sentences in 10.csv ##\n",
    "            \n",
    "for i in range(len(df10)):                                                 #test_sentence\n",
    "    \n",
    "    \n",
    "    temp= filtering(df10.text[i].split())                                  #filters and makes of words in test sentence\n",
    "    #temp = list(Counter(temp))\n",
    "\n",
    "    #print(temp)                                                           #prints all the words cosidered in test sentence\n",
    "    p1=np.ones((1,n_fv2))                                                  #p1 contains posterior prob of each class\n",
    "    \n",
    "    \n",
    "    for j in temp:                                          #for each word in test sentence multiplying class condn prob to p1\n",
    "        for k in range(n_fv2):\n",
    "            if j==vocab_2[k]:\n",
    "                p1 =np.multiply(class_cond2[k],p1)                       #if a word is not in vocab then it ignores the word\n",
    "                break\n",
    "       \n",
    "                                                          #p1 now has product of class_cond prob of each word in test sentence \n",
    "        \n",
    "    \n",
    "    p1 = np.multiply(np.array(PD_w[0:]),p1)                                # product of prior prob to all class_cond prob\n",
    "    p1 = p1/np.sum(p1,axis=1)                                              # converting p1 in probability\n",
    "    \n",
    "    \n",
    "    print(i+1,df10.text[i], vocab_2[np.argmax(p1,axis=1)[0]])                           #prints results\n",
    "    print('  Prob of chosen word =',np.max(p1,axis=1)[0])\n",
    "    print('\\n')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
